irf<-irf(vars, impulse = "cPR", response = "ADR",cumulative=F, boot =F, n.ahead = 20, runs=100,ortho = TRUE,ci=0.95)
irf<-irf(vars, impulse = "Neoplasms", response = "ADR",cumulative=F, boot =F, n.ahead = 20, runs=100,ortho = TRUE,ci=0.95)
irf<-irf(vars, impulse = "Neoplasms", response = "CBR",cumulative=F, boot =F, n.ahead = 20, runs=100,ortho = TRUE,ci=0.95)
irf<-irf(vars, impulse = "Neoplasms", response = "CBR",cumulative=F, boot =T, n.ahead = 20, runs=100,ortho = TRUE,ci=0.95)
plot(irf)
irf<-irf(vars, impulse = "Neoplasms", response = "LE",cumulative=F, boot =T, n.ahead = 20, runs=100,ortho = TRUE,ci=0.95)
plot(irf)
view(sarah)
View(sarah)
#Fitting our model (we chose model 5 as the best model)
#Trying diffrent predictors (backward seletion criteria)
obj_2r_trial<-obj_2r #model1
Ytest <- obj_2r_trial[nrow(obj_2r_trial), 1:16]
Y <- obj_2r_trial[-nrow(obj_2r_trial), 1:16]
X <- obj_2r_trial[-nrow(obj_2r_trial), 17:23]
VARXfit <- sparseVARX(Y=Y, X=X,p=4,s=4,VARXpen = "L1")
c1<-VARXfit[["Phihat"]]
c2<-VARXfit[["Bhat"]]
rownames(c1)<-colnames(obj_2r_trial[,c(1:16)])
rownames(c2)<-colnames(obj_2r_trial[,c(1:16)])
plotMatrix(c1)
plotMatrix(c2)
#fastvar pack (bad warnings) (good results)
Var2<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=4,b=4, getdiag=T,h=1)
#fastvar pack (bad warnings) (good results)
Var<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=4,b=4, getdiag=T,h=1)
coef5<-coef(Var)
pheatmap(coef5, cluster_rows = T, cluster_cols = TRUE)
#fastvar pack (bad warnings) (good results)
Var<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=2,b=2, getdiag=T,h=1)
pheatmap(coef5, cluster_rows = T, cluster_cols = TRUE)
coef5<-coef(Var)
pheatmap(coef5, cluster_rows = T, cluster_cols = TRUE)
#fastvar pack (bad warnings) (good results)
Var<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=1,b=1, getdiag=T,h=1)
coef5<-coef(Var)
pheatmap(coef5, cluster_rows = T, cluster_cols = TRUE)
var
Var
coef5
#fastvar pack (bad warnings) (good results)
Var<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=2,b=2, getdiag=T,h=1)
coef5<-coef(Var)
coef5
#fastvar pack (bad warnings) (good results)
Var<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=2,b=2, getdiag=T,h=1)
coef5<-coef(Var)
pheatmap(coef5, cluster_rows = T, cluster_cols = TRUE)
Var
Ytest <- obj_2r_trial[nrow(obj_2r_trial), 1:16]
Y <- obj_2r_trial[-nrow(obj_2r_trial), 1:16]
X <- obj_2r_trial[-nrow(obj_2r_trial), 17:23]
VARXfit <- sparseVARX(Y=Y, X=X,p=4,s=4,VARXpen = "L1")
c1<-VARXfit[["Phihat"]]
colnames(c1)<-rownames(coef5[c(2:57),])
rownames(c1)<-colnames(obj_2r_trial[,c(1:16)])
plotMatrix(c1)
c2<-VARXfit[["Bhat"]]
colnames(c2)<-rownames(coef1)[3:18]
rownames(c2)<-colnames(obj_2r_trial[,c(1:16)])
plotMatrix(c2)
c1<-VARXfit[["Phihat"]]
plotMatrix(c1)
y<- matrix(obj_2r_trial[,c(1:16)],25,16)
x<-matrix(obj_2r_trial[,c(17:23)],25,7)
fit<-fitVARX(y, p = 4, x, m = 4,penalty = "ENET", method = "cv")
forecast<-computeForecasts(fit,10)
forecast
VARXpredict(obj_2r_trial[,c(1:16)]), obj_2r_trial[,c(17:23)]), 4, 4, coef5,  n.ahead = 1)
VARXpredict(obj_2r_trial[,c(1:16)], obj_2r_trial[,c(17:23)], 4, 4, coef5,  n.ahead = 1)
predict(obj_2r_trial[,c(1:16)], obj_2r_trial[,c(17:23)], 4, 4, coef5,  n.ahead = 1)
predict(Var,  n.ahead = 1)
predict(Var,  n.ahead = 10)
#fastvar pack (bad warnings) (good results)
Var500<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=2,b=2, getdiag=T,h=1)
predict(Var,  n.ahead = 1)
predict<-predict(Var500,  n.ahead = 1)
predict
VARX = function(y, freq = rep(NA,ncol(y)), x, p=1, b=1, intercept=T, weights=NULL, l2penalty=NULL, getdiag=T) {
if (p < 1) stop("p must be a positive integer")
if (missing(x)) {
return (VAR(y, freq, p, intercept, weights, l2penalty, getdiag))
}
y.seasons = deseason(y, freq)
var.z = VARX.Z(y.seasons$remaining, x, p, b, intercept)
if (!is.null(weights) & !is.vector(weights)) {
weights = switch(weights,
exponential = exponentialWeights(var.z$Z, var.z$y.p),
linear = linearWeights(var.z$Z, var.z$y.p))
}
if (is.null(l2penalty)) {
#model = lm(var.z$y.p ~ -1 + var.z$Z, weights = weights)
model = fastMlm(var.z$Z, var.z$y.p, weights)
if (sum(is.na(coef(model))) > 0) {
warning("Multivariate lm has invalid coefficients.
Check the rank of the design matrix")
}
result = structure(list(
model = model,
var.z = var.z,
seasons = y.seasons
), class="fastVAR.VARX")
} else {
#Compute full path ridge solution
result = structure(list(
model = structure(list(ridgePath = ridgePath(var.z$y.p, var.z$Z, weights),
l2penalty = l2penalty),
class="fastVAR.RidgePath"),
var.z = var.z,
seasons = y.seasons),
class="fastVAR.VARX")
}
if (getdiag) result$diag = VAR.diag(result)
return (result)
}
#' VARX Coefficients
#'
#' If the VARX object was fit using a l2 penalty, then the full ridge path was
#' calculated and stored in the object.  This means the user can adjust the ridge penalty
#' term here and recompute the coefficients of the VARX
#' @param VARX an object of class fastVAR.VARX
#' @param ... if VAR was fit using a l2 penalty, the user can specify a different
#'   l2 penalty here and have the coefficients recomputed
#' @return The coefficients for the VARX model
#' @method coef fastVAR.VARX
#' @S3method coef fastVAR.VARX
coef.fastVAR.VARX = function(VARX, ...) {
coef(VARX$model, ...)
}
#' VARX Predict
#'
#' Predict n steps ahead from a fastVAR.VARX object
#' @param VARX an object of class fastVAR.VARX returned from VARX
#' @param xnew a matrix of future values for the exogenous inputs.  Should contain
#'   n.ahead rows
#' @param n.ahead number of steps to predict
#' @param threshold threshold prediction values to be greater than this value
#' @param ... extra parameters to pass into the coefficients method
#'   for objects of type fastVAR.VARX
#' @examples
#'   data(Canada)
#'   x = matrix(rnorm(84*4), 84, 4)
#'   predict(VARX(Canada, x = x, p = 3, b = 2, intercept = F), xnew = matrix(rnorm(2*4),2,4), n.ahead = 2)
#' @method predict fastVAR.VARX
#' @S3method predict fastVAR.VARX
predict.fastVAR.VARX = function(VARX, xnew, n.ahead=1, threshold, ...) {
freq = VARX$seasons$freq
freq.indices = which(!is.na(VARX$seasons$freq))
if (missing(xnew)) {
if (length(freq.indices) > 0)
return (VARX$var.z$Z %*% coef(VARX) +
VARX$seasons$seasonal[-(1:VARX$var.z$p),])
else
return (VARX$var.z$Z %*% coef(VARX))
}
if (nrow(xnew) != n.ahead) stop("xnew should have n.ahead rows")
y.pred = matrix(nrow=n.ahead, ncol=ncol(VARX$var.z$y.orig))
colnames(y.pred) = colnames(VARX$var.z$y.orig)
y.orig = VARX$var.z$y.orig
for (i in 1:n.ahead) {
Z.ahead.y = as.vector(t(y.orig[
((nrow(y.orig)):
(nrow(y.orig)-VARX$var.z$p+1))
,]))
if (VARX$var.z$b == 0) {
Z.ahead.x = xnew[i,]
} else {
Z.ahead.x = as.vector(t(VARX$var.z$x.orig[
((nrow(VARX$var.z$x.orig)):
(nrow(VARX$var.z$x.orig)-VARX$var.z$b+1))
,]))
}
if(VARX$var.z$intercept) Z.ahead = c(1, Z.ahead.y, Z.ahead.x)
else Z.ahead = c(Z.ahead.y, Z.ahead.x)
y.ahead = Z.ahead %*% coef(VARX)
if (!missing(threshold)) {
threshold.indices = which(y.ahead < threshold)
if (length(threshold.indices) > 0)
y.ahead[threshold.indices] = threshold
y.ahead[threshold.indices] = threshold
}
y.pred[i,] = y.ahead
if (i == n.ahead) break
y.orig = rbind(y.orig, y.ahead)
VARX$var.z$x.orig = rbind(VARX$var.z$x.orig, xnew[i,])
}
if (length(freq.indices) > 0) {
lastSeason = lastPeriod(VARX$seasons) #returns a list
y.pred.seasonal = sapply(freq.indices, function(i) {
season.start = periodIndex(freq[i], nrow(VARX$var.z$y.orig) + 1)
season.end = season.start + n.ahead - 1
rep(lastSeason[[i]], ceiling(n.ahead / freq[i]))[season.start : season.end]
})
y.pred[,freq.indices] = y.pred[,freq.indices] + y.pred.seasonal
return (y.pred)
}
else return (y.pred)
}
AR.diag = function(VAR) {
ZTZ.inv = .inverseCovariance(VAR$var.z$Z)
residual = VAR$var.z$y.p - VAR$var.z$Z %*% coef(VAR)
residual.cov = t(residual) %*% residual  #residual covariance matrix
sigma.hat = (1 / (VAR$var.z$T - VAR$var.z$k)) *
(residual.cov)
cov.hat = kronecker(sigma.hat, ZTZ.inv)
se = matrix(sqrt(diag(cov.hat)), nrow=nrow(coef(VAR)), ncol=ncol(coef(VAR)))
tvalue = coef(VAR) / se
pvalue = 2*(1 - pt(abs(tvalue),VAR$var.z$dof))
rownames(se) = colnames(VAR$var.z$Z)
rownames(tvalue) = colnames(VAR$var.z$Z)
rownames(pvalue) = colnames(VAR$var.z$Z)
colnames(se) = colnames(VAR$var.z$y.p)
colnames(tvalue) = colnames(VAR$var.z$y.p)
colnames(pvalue) = colnames(VAR$var.z$y.p)
#Get model selection statistics
sigma.tilde = 1 / VAR$var.z$T * residual.cov
sigma.tilde.det = log(det(sigma.tilde))
n = ncol(VAR$var.z$y.p)
AIC = sigma.tilde.det + 2/VAR$var.z$T * VAR$var.z$p * n^2
BIC = sigma.tilde.det + log(VAR$var.z$T)/VAR$var.z$T * VAR$var.z$p * n^2
HQ = sigma.tilde.det + 2*log(log(VAR$var.z$T))/VAR$var.z$T * VAR$var.z$p * n^2
return (list(
se=se,
tvalue=tvalue,
pvalue=pvalue,
residual=residual,
cov=cov.hat,
AIC=AIC,
BIC=BIC,
HQ=HQ
))
}
VARXpredict(obj_2r_trial[,c(1:16)]), obj_2r_trial[,c(17:23)]), 4, 4, coef5,  n.ahead = 1)
VARXpredict(obj_2r_trial[,c(1:16)], obj_2r_trial[,c(17:23)], 4, 4, coef5,  n.ahead = 1)
predict.fastVAR.VARX(Var500,  n.ahead = 1)
predict<-predict(Var500,xnew=obj_2r_trial[26,c(17:23)], n.ahead = 1)
obj_2r_trial[26,c(17:23)]
dim(obj_2r_trial[26,c(17:23)])
dim(t(obj_2r_trial[26,c(17:23)]))
predict<-predict(Var500,xnew=t(obj_2r_trial[26,c(17:23)]), n.ahead = 1)
predict
predict<-predict(Var500,xnew=t(obj_2r_trial[25:26,c(17:23)]), n.ahead = 2)
predict<-predict(Var500,xnew=t(obj_2r_trial[c(25:26),c(17:23)]), n.ahead = 2)
predict<-predict(Var500,xnew=(obj_2r_trial[c(25:26),c(17:23)]), n.ahead = 2)
predict
VAR.diag(Var500)
results_lin <- lp_lin(obj_2r_trial[,c(1:7)],
lags_endog_lin = 4,
trend = 0,
shock_type = 1,
confint = 1.96,
hor = 12,
exog_data = obj_2r_trial[,c(17:18)],
lags_exog = 4,
contemp_data = contemp_data)
results_lin <- lp_lin(obj_2r_trial[,c(1:7)],
lags_endog_lin = 4,
trend = 0,
shock_type = 1,
confint = 1.96,
hor = 12,
exog_data = obj_2r_trial[,c(17:18)],
lags_exog = 4)
as.data.frame(obj_2r_trial)
results_lin <- lp_lin(obj_2r_trial[,c(1:7)],
lags_endog_lin = 4,
trend = 0,
shock_type = 1,
confint = 1.96,
hor = 12,
exog_data = obj_2r_trial[,c(17:18)],
lags_exog = 4)
as.data.frame(obj_2r_trial)
results_lin <- lp_lin(obj_2r_trial[,c(1:7)],
lags_endog_lin = 4,
trend = 0,
shock_type = 1,
confint = 1.96,
hor = 12,
exog_data = obj_2r_trial[,c(17:18)],
lags_exog = 4)
results_lin <- lp_lin(obj_2r_trial[,c(1:7)],
lags_endog_lin = 1,
trend = 0,
shock_type = 1,
confint = 1.96,
hor = 12,
exog_data = obj_2r_trial[,c(17:18)],
lags_exog = 1)
results_lin <- lp_lin(as.data.frame(obj_2r_trial[,c(1:7)]),
lags_endog_lin = 1,
trend = 0,
shock_type = 1,
confint = 1.96,
hor = 12,
exog_data =as.data.frame(obj_2r_trial[,c(17:18)]),
lags_exog = 1)
plot(results_lin)
.sparseVARX = function(j, y, x, p, b, Z, y.spec, x.spec, alpha) {
colIndex = j[1]
x.to.remove = which(!x.spec[colIndex,])
y.to.remove = which(!y.spec[colIndex,])
np = ncol(y) * p
z.x.to.remove = c()
z.y.to.remove = c()
if(length(x.to.remove) > 0) {
z.x.to.remove = as.vector(sapply(1:b, function(ii) {
(x.to.remove + 1) + np + ncol(x)*(ii-1)
}))
}
if(length(y.to.remove) > 0) {
z.y.to.remove = as.vector(sapply(1:p, function(ii) {
(y.to.remove + 1) + ncol(y)*(ii-1)
}))
}
z.to.remove = unlist(c(z.x.to.remove, z.y.to.remove))
if(length(z.to.remove > 0)) {
Z.reduced = Z[,-z.to.remove]
}
else {
Z.reduced = Z
}
return (cv.glmnet(Z.reduced[,-1], j[-1], alpha=alpha))
}
#' Sparse Vector Autoregression with Exogenous Inputs
#'
#' Fit a VARX model with lasso penalty.
#' The VAR model is estimated using a multiresponse linear regression.
#' The sparse VAR fits multiple uniresponse linear regressions with lasso penalty.
#' mclapply from multicore can be used to fit the individual uniresponse
#' linear regressions in parallel.  Note that mclapply is not available for windows
#' @param y A matrix of endogenous variables where each column represents an individual time series
#' @param freq only used if the time series are periodic.  freq is a vector of
#'   frequencies for each of the time series, as in 'ts(y, freq = ...)'.
#'   If the time series are not periodic, then this vector can be a vector of NA
#' @param x A matrix of exogenous variables where each column represents an individual time series
#' @param p the number of lags of Y to include in the design matrix
#' @param b the number of lags to X include in the design matrix
#' @param y.spec A binary matrix that can constrain the number of lagged predictor variables.
#'   If y.spec[i][j] = 0, the ith time series in y will not be regressed on the jth
#'   time series of y, or any of its lags.
#' @param x.spec A binary matrix that can constrain the number of lagged exogenous variables.
#'   If x.spec[i][j] = 0, the ith time series in y will not be regressed on the jth
#'   time series of x, or any of its lags.
#' @param numcore number of cpu cores to use to parallelize this function
#' @param alpha the elastic net mixing parameter, as defined in 'glmnet'
#' @examples
#'   data(Canada)
#'   x = matrix(rnorm(84*4), 84, 4)
#'   SparseVARX(Canada, x = x, p = 3, b = 2)
#' @export
SparseVARX = function(y, freq=rep(NA,ncol(y)), x, p, b,
y.spec=matrix(1,nrow=ncol(y),ncol=ncol(y)),
x.spec=matrix(1,nrow=ncol(y),ncol=ncol(x)),
numcore=1, alpha=0.8, ...) {
if (p < 1) stop("p must be a positive integer")
if (!is.matrix(y)) {
stop("y must be a matrix (not a data frame).  Consider using as.matrix(y)")
}
if (missing(x)) {
return (SparseVAR(y, freq, p, y.spec, numcore))
}
y.seasons = deseason(y, freq)
var.z = VARX.Z(y.seasons$remaining,x,p,b,intercept=T)
Z = var.z$Z
y.augmented = rbind(1:ncol(y),var.z$y.p)
if (numcore==1) {
var.lasso = apply(y.augmented, 2, .sparseVARX, y=y,x=x,p=p,b=b,
Z=Z, y.spec=y.spec, x.spec=x.spec, alpha=alpha)
} else {
y.augmented.list = c(unname(as.data.frame(y.augmented)))
var.lasso = mclapply(y.augmented.list, .sparseVARX,
y=y,x=x,p=p,b=b,
Z=Z,
y.spec=y.spec, x.spec=x.spec,
mc.cores=numcore, ...)
}
return(structure (list(
model = var.lasso,
var.z = var.z,
seasons = y.seasons),
class="fastVAR.SparseVARX"))
}
#' Coefficients of a SparseVARX model
#'
#' The underlying library, glmnet, computes the full path to the lasso.
#' This means it is computationally easy to compute the lasso solution
#' for any penalty term.  This function allows you to pass in the desired
#' l1 penalty and will return the coefficients
#' @param sparseVARX an object of class fastVAR.SparseVARX
#' @param l1penalty The l1 penalty to be applied to the SparseVARX
#'   model.
#' @method coef fastVAR.SparseVARX
#' @S3method coef fastVAR.SparseVARX
coef.fastVAR.SparseVARX = function(sparseVARX, l1penalty) {
if (missing(l1penalty)) {
B = data.frame(lapply(sparseVARX$model, function(model) {
as.vector(coef(model, model$lambda.min))
}))
}
else if (length(l1penalty) == 1) {
B = data.frame(lapply(sparseVARX$model, function(model) {
as.vector(coef(model, l1penalty))
}))
} else {
B = matrix(0, nrow=ncol(sparseVARX$var.z$Z), ncol=ncol(sparseVARX$var.z$y.p))
for (i in 1:length(l1penalty)) {
B[,i] = as.vector(coef(sparseVARX$model[[i]], l1penalty[i]))
}
}
colnames(B) = colnames(sparseVARX$var.z$y.orig)
rownames(B) = colnames(sparseVARX$var.z$Z)
return (as.matrix(B))
}
#' SparseVARX Predict
#'
#' Predict n steps ahead from a fastVAR.SparseVARX object
#' @param sparseVARX an object of class fastVAR.SparseVARX returned from SparseVARX
#' @param xnew a matrix of future values for the exogenous inputs.  Should contain
#'   n.ahead rows
#' @param n.ahead number of steps to predict
#' @param threshold threshold prediction values to be greater than this value
#' @param ... extra parameters to pass into the coefficients method
#'   for objects of type fastVAR.VAR
#' @examples
#'   data(Canada)
#'   x = matrix(rnorm(84*4), 84, 4)
#'   predict(SparseVARX(Canada, x = x, p = 3, b = 2), xnew=matrix(rnorm(2*4),2,4), n.ahead=2)
#' @method predict fastVAR.SparseVARX
#' @S3method predict fastVAR.SparseVARX
predict.fastVAR.SparseVARX = function(sparseVARX, xnew, n.ahead=1, threshold, ...) {
freq = sparseVARX$seasons$freq
freq.indices = which(!is.na(sparseVARX$seasons$freq))
if (missing(xnew)) {
if (length(freq.indices) > 0)
return (sparseVARX$var.z$Z %*% coef(sparseVARX) +
sparseVARX$seasons$seasonal[-(1:sparseVARX$var.z$p),])
else
return (sparseVARX$var.z$Z %*% coef(sparseVARX))
}
if (nrow(xnew) != n.ahead) stop("xnew should have n.ahead rows")
y.pred = matrix(nrow=n.ahead, ncol=ncol(sparseVARX$var.z$y.orig))
colnames(y.pred) = colnames(sparseVARX$var.z$y.orig)
y.orig = sparseVARX$var.z$y.orig
for (i in 1:n.ahead) {
Z.ahead.y = as.vector(t(y.orig[
((nrow(y.orig)):
(nrow(y.orig)-sparseVARX$var.z$p+1))
,]))
if(sparseVARX$var.z$b == 0) {
Z.ahead.x = xnew[1,]
} else {
Z.ahead.x = as.vector(t(sparseVARX$var.z$x.orig[
((nrow(sparseVARX$var.z$x.orig)):
(nrow(sparseVARX$var.z$x.orig)-sparseVARX$var.z$b+1))
,]))
}
Z.ahead = c(1, Z.ahead.y, Z.ahead.x)
y.ahead = Z.ahead %*% coef(sparseVARX, ...)
if(!missing(threshold)) {
threshold.indices = which(y.ahead < threshold)
if(length(threshold.indices) > 0)
y.ahead[threshold.indices] = threshold
}
y.pred[i,] = y.ahead
if (i == n.ahead) break
y.orig = rbind(y.orig, y.ahead)
sparseVARX$var.z$x.orig = rbind(sparseVARX$var.z$x.orig, xnew[1,])
}
if (length(freq.indices) > 0) {
lastSeason = lastPeriod(sparseVARX$seasons) #returns a list
y.pred.seasonal = sapply(freq.indices, function(i) {
season.start = periodIndex(freq[i], nrow(sparseVARX$var.z$y.orig) + 1)
season.end = season.start + n.ahead - 1
rep(lastSeason[[i]], ceiling(n.ahead / freq[i]))[season.start : season.end]
})
y.pred[,freq.indices] = y.pred[,freq.indices] + y.pred.seasonal
return (y.pred)
}
else return (y.pred)
}
sparseVARX(obj_2r_trial[,c(1:16)], x=obj_2r_trial[,c(17:23)],4,4)
sparseVARX(obj_2r_trial[,c(1:16)], obj_2r_trial[,c(17:23)],4,4)
sparse<-sparseVARX(obj_2r_trial[,c(1:16)], obj_2r_trial[,c(17:23)],4,4)
sparse
coef.fastVAR.SparseVARX(sparse,l1penalty)
coef.fastVAR.SparseVARX(sparse)
coef(sparse)
VAR.diag(sparse)
coef.fastVAR.SparseVARX(sparseVARX = sparse,l1penalty = T)
coef(sparse)
coef(sparse)
diag<-VAR.diag(sparse)
coef(Var500)
plotMatrix(coef(Var500))
plotMatrix(t(coef(Var500)))
Var.diag(Var500)
VAR.diag(Var500)
#fastvar
Var500<-SparseVARX(y=as.matrix(obj_2r_trial[,c(1:16)]), x=obj_2r_trial[,c(17:23)],p=4,b=4, getdiag=T,h=1)
coef.fastVAR.SparseVARX(sparse,l1penalty)
coef.fastVAR.SparseVARX(Var500)
VAR.diag(Var500)
tiff(filename = "Fastvar,l1.tiff",
width = 5000, height = 3500, units = "px", pointsize = 10,
compression = "lzw",res=400)
plotMatrix(t(coef(Var500)))
dev.off()
plotMatrix(t(coef(Var500)))
VARstep(obj_2r_trial[,c(1:16)]), 7)
VARstep(obj_2r_trial[,c(1:16)], 7)
savehistory("C:/Users/Sara/Desktop/Fastvar.Rhistory")
